{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "jSNrdDLdyjHi",
        "QnQJUyCL1RIM"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cmucung/eye-retina-disease-classification/blob/main/CNNs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lesson 3 - Introduction to CNNs\n",
        "===============================\n",
        "\n",
        "@AIS 2023 (adapted from @AI4ALL 2022 code)\n",
        "\n",
        "TA: Priyanshi\n",
        "\n",
        "In this notebooke, we use Tensorflow/Keras library to play with CNNs.\n",
        "\n",
        "Keras Documentation: https://keras.io/\n",
        "\n",
        "Section Overview\n",
        "- ✅ Importing Dependencies\n",
        "- ✅ Visualizing an Image through CNN\n",
        "- ✅ Loading MNIST dataset\n",
        "- ✅ Constructing a CNN\n",
        "- ✅ Training a CNN\n",
        "- ✅ Playground"
      ],
      "metadata": {
        "id": "nEyhpZbzw0K-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing Dependencies\n",
        "-----------------------"
      ],
      "metadata": {
        "id": "9txo4Rp7xIEu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "UXxcXhQRwXYd"
      },
      "outputs": [],
      "source": [
        "!git clone -q https://github.com/Srinivas-R/AI4ALL.git\n",
        "\n",
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "from scipy import signal\n",
        "import requests\n",
        "import io\n",
        "import os\n",
        "from urllib.request import urlopen\n",
        "from PIL import Image\n",
        "import pandas as pd\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "from keras import backend as K\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.applications.vgg16 import preprocess_input\n",
        "from keras.preprocessing import image\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Part 1: Using Pre-Trained Models\n",
        "------------------------------\n",
        "\n",
        "We use a pretrained `VGG16` CNN."
      ],
      "metadata": {
        "id": "lzF4yzyKyzUx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# LOAD PRETRAINED VGG16\n",
        "base_model = VGG16(weights='imagenet', include_top=False)"
      ],
      "metadata": {
        "id": "w70OKzc6yc4Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d9b392e-6ea7-4632-fe60-4d30a1ff199d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58889256/58889256 [==============================] - 1s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Part 2: Build Your Own Model:\n",
        "----------------------"
      ],
      "metadata": {
        "id": "VXB4oK3IJH5Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "###Loading your Dataset\n",
        "\n",
        "Load and visualize your dataset."
      ],
      "metadata": {
        "id": "MJoVRbTK4ON9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "# EXERCISE 1 : LOAD YOUR OWN DATASET HERE\n",
        "\n",
        "directory= \"/content/drive/MyDrive/Group 4/Retina Classification/Dataset/archive/Training_Set/Training_Set/Training\"\n",
        "training_files = [file for file in os.listdir(directory) if file.endswith('.png')]\n",
        "image_data = []\n",
        "\n",
        "for file in training_files:\n",
        "    file_path = os.path.join(directory, file)\n",
        "    with Image.open(file_path) as img:\n",
        "        width, height = img.size\n",
        "\n",
        "    image_data.append({\n",
        "        'File Name': file,\n",
        "        'Width': width,\n",
        "        'Height': height,\n",
        "        # Add more features when we need\n",
        "    })\n",
        "\n",
        "df = pd.DataFrame(image_data)\n",
        "print(df.head())\n",
        "\n",
        "num_classes = 2\n"
      ],
      "metadata": {
        "id": "ZmShRDXt4Q_w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1416fe53-57be-40a0-b52d-6e4602f8ca82"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "  File Name  Width  Height\n",
            "0  1024.png   2144    1424\n",
            "1  1018.png   2144    1424\n",
            "2  1019.png   2144    1424\n",
            "3  1025.png   2144    1424\n",
            "4  1031.png   2144    1424\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualize the dataset."
      ],
      "metadata": {
        "id": "8pCWT57q4iiN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rand_idx = np.random.randint(0, len(x_train))\n",
        "# EXERCISE 3: VISUALISE AN IMAGE FROM YOUR DATASET\n",
        "input_shape = (x_train.shape[1], x_train.shape[2], 1)\n",
        "print('Input Shape: ', input_shape)\n",
        "print('Label: ', y_train[rand_idx])\n",
        "\n",
        "\n",
        "example = x_train[rand_idx, :, :]\n",
        "plt.imshow(example, cmap='gray')"
      ],
      "metadata": {
        "id": "rSnJGfb-4kUn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "outputId": "6bec5f71-9e48-4c9d-eec2-308b6fb25fb2"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'x_train' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-f8e32b645daf>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrand_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# EXERCISE 3: VISUALISE AN IMAGE FROM YOUR DATASET\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0minput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Input Shape: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Label: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrand_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'x_train' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Constructing a CNN\n",
        "\n",
        "Construct a CNN with keras.Sequential()"
      ],
      "metadata": {
        "id": "bwCqoTAd6qPM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.Sequential() #Step #1: Define the model\n",
        "\n",
        "_, height, width = x_train.shape\n",
        "depth = 1 # 1 for grayscale images\n",
        "input_shape = (height, width, depth)\n",
        "\n",
        "print(f\"Input Shape:\", input_shape)\n",
        "#Step 2: Add layers to the model:\n",
        "\n",
        "# BLOCK 1\n",
        "model.add(layers.Conv2D(filters=8, kernel_size=(3, 3), padding=\"same\", activation=\"relu\", input_shape=input_shape))\n",
        "model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "# BLOCK 2\n",
        "model.add(layers.Conv2D(filters=8, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"))\n",
        "model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "# CLASSIFIER\n",
        "model.add(layers.MaxPooling2D(pool_size=(7, 7)))\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(num_classes))\n",
        "model.add(layers.Activation(\"softmax\"))\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "71NcJxH16thY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question: Can you figure out the logic for computing number of params ?"
      ],
      "metadata": {
        "id": "B7gIzOu6mvMi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Training a CNN\n",
        "\n",
        "Define hyperparameters and train the CNN."
      ],
      "metadata": {
        "id": "5BmPFa1Y9-0i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define hyperparameters."
      ],
      "metadata": {
        "id": "fyqYRH_G8DdQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# HYPERPARAMETRS\n",
        "\n",
        "# num_epochs - number of times to repeat the training\n",
        "num_epochs = 10\n",
        "\n",
        "# batch_size - how many images to train together at each step\n",
        "batch_size = 128\n",
        "\n",
        "# learning_rate - the update speed of the network\n",
        "learning_rate = 1e-3"
      ],
      "metadata": {
        "id": "Bq2lKb847w_w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compile and start training."
      ],
      "metadata": {
        "id": "t2Nvq7-l8I8v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss=keras.losses.categorical_crossentropy,\n",
        "              optimizer=keras.optimizers.Adam(learning_rate=learning_rate), metrics=['accuracy']) #Step 3: Compile\n",
        "\n",
        "history = model.fit(x_train, y_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=num_epochs,\n",
        "          verbose=1) #Step 4: Train the model\n",
        "\n"
      ],
      "metadata": {
        "id": "gxAc1GUb71WT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Run Inference on New Data\n"
      ],
      "metadata": {
        "id": "jSNrdDLdyjHi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img_index = 23 #pick an image to test on from our test array, or try selecting it randomly like we did for visualization!\n",
        "\n",
        "print(f\"Running Model Inference on Image number {img_index}\")\n",
        "img_array = x_test[img_index]\n",
        "expanded_img_array = np.expand_dims(img_array, axis=(0, 3))\n",
        "\n",
        "actual_label = y_test[img_index]\n",
        "actual_label = np.argmax(actual_label)\n",
        "# Make predictions using the model\n",
        "predictions = model.predict(expanded_img_array)\n",
        "predicted_label = np.argmax(predictions[0])  # Get the predicted label\n",
        "\n",
        "print(\"Predicted Label:\", predicted_label)\n",
        "print(\"Actual Label:\", actual_label)\n"
      ],
      "metadata": {
        "id": "BHtl48mRvfr2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "QsbvJ7dmze0Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Cross-Validation\n",
        "\n",
        "We can use the entirety of the test arrays to compute our model's accuracy and loss on new data to see how it performs."
      ],
      "metadata": {
        "id": "QnQJUyCL1RIM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "score = model.evaluate(x_test, y_test, verbose=0) #Step 5: Cross Validation\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "metadata": {
        "id": "RlmLHwVLzela"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For any model, our aim is to minimize the \"loss\" and maximize the \"accuracy\". Here accuracy is the cross-validation probability of the event\n",
        "(predicted label = actual label)."
      ],
      "metadata": {
        "id": "8_ukmvub1oy4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Saving and Loading the model\n",
        "\n",
        "We can also save the model for future use."
      ],
      "metadata": {
        "id": "M_bhLATx18nD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the model and its weights\n",
        "model.save(\"path_to_save_model.h5\")\n",
        "\n",
        "# Load the saved model\n",
        "loaded_model = keras.models.load_model(\"/content/path_to_save_model.h5\")"
      ],
      "metadata": {
        "id": "20P35oSb2TRv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Playground\n",
        "----------\n",
        "Try new ideas and play with CNN architecture."
      ],
      "metadata": {
        "id": "1j8aL6ya-F1J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "How can we improve model accuracy? Messs around with model architecture and hyperparams to see how it impacts model performance. Here are some ideas\n",
        "\n",
        "###Conv2D arguments\n",
        "\n",
        "- Increase Conv2D channels (aka filters)?\n",
        "- Kernel Size: Adjust the kernel_size parameter in the Conv2D layer to change the size of the convolutional filter. Experiment with different kernel sizes (e.g., 3x3, 5x5) to observe the impact on the model's ability to capture different spatial features.\n",
        "\n",
        "###Layers:\n",
        "\n",
        "- Increase the depth: Add more Conv2D layers to the network to increase its depth. You can stack additional convolutional layers to allow the model to learn more complex features and representations.\n",
        "\n",
        "- Modify the pooling layers: Experiment with adding more MaxPooling2D layers or changing their sizes to alter the downsampling process. This can impact the spatial resolution of the feature maps and the amount of information preserved.\n",
        "\n",
        "- Change the Dense layers: Add more Dense layers in the classifier part of the network to increase its capacity. You can also experiment with different activation functions in these layers to observe their effect on the model's performance.\n",
        "\n",
        "###Training Hyperparameters\n",
        "\n",
        "- Activation Function: Try using different activation functions in the Conv2D and Dense layers, such as ReLU, sigmoid, or tanh. Each activation function has different properties that can impact the model's ability to learn and converge.\n",
        "- Learning Rate: Experiment with different learning rates to observe their effect on the training process. Higher learning rates may result in faster convergence but may also introduce instability, while lower learning rates may slow down convergence but provide more stable learning.\n",
        "- Number of Epochs: Increase or decrease the number of training epochs to see how it affects the model's performance. More epochs allow the model to learn for longer, but there's a risk of overfitting if the model is trained for too long.\n",
        "- Batch Size: Try varying the batch size used during training. Larger batch sizes may accelerate training due to more efficient parallelization, while smaller batch sizes can offer better generalization at the cost of longer training time."
      ],
      "metadata": {
        "id": "LjuKiZvC-Lc1"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4gfAzFfAbZp4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Please record what you have tried and what's the impact here."
      ],
      "metadata": {
        "id": "OSwyGGS1-qmT"
      }
    }
  ]
}